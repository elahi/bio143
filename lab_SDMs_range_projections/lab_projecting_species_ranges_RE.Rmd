---
title: "Projecting the future range of California thrashers"
author: "< your name here >"
date: "BIOHOPK 143H - Winter 2022"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height = 4, fig.width = 6)

### load the tidyverse packages
if (!require("tidyverse")) install.packages("tidyverse"); library(tidyverse)

### load the "mgcv" package for fitting GAMs
if (!require("mgcv")) install.packages("mgcv"); library(mgcv)

### load the "dismo" package, which has a bunch of helper functions for SDMs
if (!require("dismo")) install.packages("dismo"); library(dismo)
```

# Introduction

## The California thrasher

[The California thrasher](https://www.allaboutbirds.org/guide/California_Thrasher/overview) is a nonmigratory species of songbird commonly sighted in California chaparral (shrubland) ecosystems. The California thrasher is something of a famous bird in ecology and biogeography - Joseph Grinnell's 1917 paper, "[the niche-relationships of the California thrasher](https://www.jstor.org/stable/4072271?seq=1#metadata_info_tab_contents)," introduced the ecological niche concept to ecology. In the paper, Grinnell aimed to discern the processes that shaped the thrasher's notably limited geographic range, which extends from Northern Baja to Northern California.

The "Grinnellian niche," now one of several niche "concepts," defines the niche as the habitat requirements and behaviors that allow species to survive and reproduce in a given habitat. This niche concept underlies much of the modern study of biogeography and the practice of correlative species distribution modeling, which uses statistical models and machine learning algorithms to approximate the underlying determinants of species geographic ranges.

In this lab, we'll apply species distribution models to characterize the niche of the California thrasher ourselves - then, we'll take that niche model and project it forward in time using climate projections under two different emissions scenarios.

## BIOCLIM variables

In this lab, we'll work with the "BIOCLIM" variables, which are frequently used in terrestrial species distribution models and are derived from spatially-explicit monthly temperature and precipitation values. These values are not usually temporally explicit - here, we're using BIOCLIM values calculated over the period of 1970-2000. The data file for this lab ("thrasher_occurrence_data.csv") contains California thrasher presence/absence $^\Delta$ data from across the state of California, along with 19 BIOCLIM variables, plus the latitude, longitude, and elevation (in meters) associated with each point. From [the WorldClim website](https://www.worldclim.org/data/bioclim.html), the BIOCLIM variables are:

-   **BIO1** = Annual Mean Temperature

-   **BIO2** = Mean Diurnal Range (Mean of monthly (max temp - min temp))

-   **BIO3** = Isothermality (BIO2/BIO7) (×100)

-   **BIO4** = Temperature Seasonality (standard deviation ×100)

-   **BIO5** = Max Temperature of Warmest Month

-   **BIO6** = Min Temperature of Coldest Month

-   **BIO7** = Temperature Annual Range (BIO5-BIO6)

-   **BIO8** = Mean Temperature of Wettest Quarter

-   **BIO9** = Mean Temperature of Driest Quarter

-   **BIO10** = Mean Temperature of Warmest Quarter

-   **BIO11** = Mean Temperature of Coldest Quarter

-   **BIO12** = Annual Precipitation

-   **BIO13** = Precipitation of Wettest Month

-   **BIO14** = Precipitation of Driest Month

-   **BIO15** = Precipitation Seasonality (Coefficient of Variation)

-   **BIO16** = Precipitation of Wettest Quarter

-   **BIO17** = Precipitation of Driest Quarter

-   **BIO18** = Precipitation of Warmest Quarter

-   **BIO19** = Precipitation of Coldest Quarter

$^\Delta$ Actually, these are presence and *pseudo*-absence data - I've obtained presences from a citizen science database (eBird), which reflects *only* where California thrashers have been observed (not where they weren't observed), and I've created fake absence points so that these data can be used with a model that requires presence *and* absence values (i.e., any parametric statistical model such as a GLM or GAM). This is a common practice, and the method we use to construct these pseudo-absences can be important, but we're going to gloss over those complexities in this lab. Once created, we proceed with these data as if they were real presence-absence data.

## Future climate estimates

We can partition future uncertainty about climate change into three components: (1) uncertainty in future greenhouse gas emissions, (2) differences in modeling methodologies, and (3) uncertainty pertaining to each model.

Uncertainty in emissions arises from the fact that we can't predict many of the factors that control emissions - government policies, technological development, global inequality and international politics, for example. Rather than choose a "most likely" scenario, the IPCC relies on several different scenarios, called "[Shared Socioeconomic Pathways](https://www.carbonbrief.org/explainer-how-shared-socioeconomic-pathways-explore-future-climate-change)" (SSPs). These SSPs range from a path of sustainability in which global emissions decline alongside material growth and resource use (SSP1), to a world in which fossil fuel use is ever increasing (SSP5). Here, we'll use SSP2-4.5, a "middle of the road" scenario limiting global warming to 3C by 2100, and SSP5-8.5, a "worst case" scenario with warming above 4C.

While characterizing changes in global mean temperature as a result of increased atmospheric CO~2~ is *relatively* straightforward, obtaining spatially explicit forecasts of the the impacts of climate change is much less so - consider, for example, the uncertainty in weather forecasts only a few days out. We overcome this in a couple of ways - first, by aggregating forecasts across large time windows (in this lab, we'll use 2081-2100), and second, by relying on *many* different climate models, each of which is validated by hindcasting (i.e., iterating the model *backward* in time instead of foward). [CMIP6](https://www.carbonbrief.org/cmip6-the-next-generation-of-climate-models-explained) includes about 100 different models from different research groups - here, we'll use just one model ([BCC-CSM2-MR](https://gmd.copernicus.org/articles/12/1573/2019/)), but when projecting future species distributions it's common to use multiple.

# 1 - Build and evaluate your SDM

Let's start by reading in the data - the thrasher occurrence data, the 1970-2000 BIOCLIM maps for California, and projections for California's climate under the SSP2-4.5 and SSP5-8.5 scenarios:

```{r}
library(here)
```


```{r}
thrasher <- read.csv(here("lab_SDMs_range_projections", "thrasher_occurrence_data.csv"))
bioclim <- read.csv(here("lab_SDMs_range_projections", "bioclim_1970-2000.csv"))
ssp245 <- read.csv(here("lab_SDMs_range_projections", "bioclim_2081-2100_ss245.csv"))
ssp585 <- read.csv(here("lab_SDMs_range_projections", "bioclim_2081-2100_ss585.csv"))
```

## Choose an initial set of predictors

**Question 1:** Read Grinnell 1917. What environmental variables (biotic or abiotic) do you think would make good predictors in a species distribution model for California thrasher?

> **Answer:**
> Humidity, temperature, elevation, chaparral habitat, 

**Question 2:** Read the descriptions of each of the BIOCLIM variables above. Choose an initial six variables that you think would be good predictors based on your knowledge of the California thrasher's ecology. Are there any variables that you'd like to include that aren't available in this dataset? If so, are there any BIOCLIM variables which might be a useful proxy for the variables you don't have?

> **Answer:**
> We chose: annual mean temperature, annual precipitation, precip seasonality, mean temp of wettest quarter, precip of wettest quarter, precip of driest quarter
> would be nice to have chaparral. 

**Remove colinear predictors:** Now, plot the six BIOLCIM variables against each other, and compute pairwise correlations among them. If a pair of variables are highly correlated (cor \> 0.9), choose which you think is most appropriate and drop the other. For example, `bio3` and `bio4` have a correlation of 0.91 in this dataset, so we would want to use either `bio3` or `bio4` in our model, but not both.

```{r}
## YOUR CODE HERE
## Subset `thrasher` data frame to your chose BIOCLIM variables
## use the `pairs()` and `cor()` functions to evaluate colinearity

d <- thrasher %>% dplyr::select(lon, lat, present, bio1, bio12, bio15, bio8, bio16, bio17)
d_env <- d %>% dplyr::select(bio1, bio12, bio15, bio8, bio16, bio17)

library(ggcorrplot)
cor_mat <- d_env %>% cor()
ggcorrplot(cor_mat, hc.order = FALSE, type = "lower",
           lab = TRUE, show.legend = T, 
           lab_size = 3, legend.title = "", 
           tl.cex = 8) 
```

I will drop bio16 (precip of wettest quarter). 

## Fit competing models

Now, let's fit multiple different models using combinations of your chosen BIOCLIM variables as predictors. In each model, you can have as few as 1 predictor or as many as 6. These will, of course, be Bernoulli GAMs. For example, we can fit a model with 3 smooth functions of BIOCLIM variables (with k = 5 basis functions each) using:

```{r eval = FALSE}
thrasher_gam <- gam(
  present ~ s(bio1) + s(bio2) + s(bio3), 
  data = thrasher, 
  family = binomial(link = "logit")
)
```

or, we can choose to make some of these predictors linear or polynomial (e.g. quadratic) terms:

```{r}
## Same predictors as above, but now we fit a quadratic effect of bio1 and a linear effect of bio3, and keep bio2 as a smooth term
thrasher_gam <- gam(
  present ~ poly(bio1, 2) + s(bio2) + bio3, 
  data = thrasher, 
  family = binomial(link = "logit")
)
```

Try at least 10 models. For each model, compute the AIC and record that AIC along with the model terms (somewhere else - you don't have to record it here). Typically, we would keep all models within 2AIC of each, and average across these models. Here though, just choose the model with the lowest AIC, or choose a model that makes the most sense to you from those within 2AIC of the "best" model's AIC. Provide the code for the best-fit model below:

```{r}
m1 <- gam(
  present ~ s(lon, lat, k = 100), 
  data = d, family = binomial(link = "logit")
)

m2 <- gam(
  present ~ s(bio1), 
  data = d, family = binomial(link = "logit")
)

m3 <- gam(
  present ~ s(bio12), 
  data = d, family = binomial(link = "logit")
)

m4 <- gam(
  present ~ s(bio15), 
  data = d, family = binomial(link = "logit")
)

m5 <- gam(
  present ~ s(bio8), 
  data = d, family = binomial(link = "logit")
)

m6 <- gam(
  present ~ s(bio17), 
  data = d, family = binomial(link = "logit")
)

# Space; annual mean temp and precip [average]
m7 <- gam(
  present ~ s(lon, lat, k = 100) + s(bio1) + s(bio12), 
  data = d, family = binomial(link = "logit")
)

# Space; precip CV; precip driest quarter; temp wettest quarter [extremes and range]
m8 <- gam(
  present ~ s(lon, lat, k = 100) + s(bio15) + s(bio8) + s(bio17), 
  data = d, family = binomial(link = "logit")
)

# All environmental, no space
m9 <- gam(
  present ~ s(bio1) + s(bio12) + s(bio15) + s(bio8) + s(bio17), 
  data = d, family = binomial(link = "logit")
)

# All
m10 <- gam(
  present ~ s(lon, lat, k = 100) + s(bio1) + s(bio12) + s(bio15) + s(bio8) + s(bio17), 
  data = d, family = binomial(link = "logit")
)

# All, but linear; DOES NOT CONVERGE
m11 <- gam(
  present ~ s(lon, lat, k = 100) + bio1 + bio12 + bio15 + bio8 + bio17, 
  data = d, family = binomial(link = "logit")
)

# All environmental, but linear
m11 <- gam(
  present ~ bio1 + bio12 + bio15 + bio8 + bio17, 
  data = d, family = binomial(link = "logit")
)

AIC(m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11)

m_best <- m10

```



**Question 3:** With this model in hand, use the `gam.check()` function to check whether the estimated degrees of freedom in each term are appropriate (a low p-value indicates that you may want to increase the number of degrees of freedom for that smooth function). Does `gam.check()` suggest that your degrees of freedom may be too low for some predictors? Do you think that increasing that degrees of freedom for these predictors makes sense ecologically or not?

> **Answer:**

```{r}
gam.check(m_best)
plot(m_best)

m_best2 <- gam(
  present ~ s(lon, lat, k = 100) + s(bio1) + s(bio12) + s(bio15) + s(bio8) + s(bio17, k = 20), 
  data = d, family = binomial(link = "logit")
)

gam.check(m_best2) # can't get the edf below the boundary; pvals remain low

plot(m_best2)
```

If you decided to increase k for any of these smooth terms, do so until the p-value for that term is non-significant. Provide the code for your final model below, if different from your previous one:

> I could not get the p-value to be non-sig; so I'll just use the original best model. 

```{r}
m_best <- gam(
  present ~ s(lon, lat, k = 100) + s(bio1) + s(bio12) + s(bio15) + s(bio8) + s(bio17), 
  data = d, family = binomial(link = "logit")
)
```

## Model Performance

**Question 4:** Use `dismo::evaluate()` to plot the ROC curve and extract the AUC value. Does your AUC score suggest that the model is able to accurately discriminate between presences and absences?

```{r}
fitted <- as.numeric(predict(m_best, type = "response"))
fitted_p <- fitted[d$present == 1]
fitted_a <- fitted[d$present == 0]

ROC <- dismo::evaluate(fitted_p, fitted_a)
plot(ROC, "ROC")
```


> **Answer:**
> Yes, the model is excellent; AUC is > 0.9. 

## Present

In your group presentation, you should cover the following things from this section:

1.  The initial set of environmental predictors you chose, and why
2.  Whether you decided to increase k for any of your smooth functions, and if so, which ones and why
3.  The final model structure and code, and the AUC score

# 2 - Model Terms

## Plotting terms

The most straightforward way to characterize the niche, in terms of each of the predictors in the model, is for us to plot the fitted model smooth functions and interpret the plots.

Let's do this for our chosen model. Use the `plot()` function to plot the smooths from the fitted model. You may also want to use the argument `scale = 0` so that the plots are not constrained to have the same y-axis, and `shade = TRUE` to produce a shaded error band (just for aesthetics, really).

```{r}
plot(m_best, scale = 0, shade = TRUE)
```

One thing that makes these a little hard to understand is the scale - our model uses a logit link, so these are on the log-odds scale, but it would be much easier to interpret these on the probability (of occurrence) scale. We can back-transform these smooth curves to the probability scale by passing a transformation function to the `trans` argument. To do this, we first extract the inverse link function (which in this case is the "logistic" or "inverse logit") from the model object.

```{r}
linkinv <- m_best$family$linkinv
linkinv
```

Now, plot the smooth functions on the transformed scale:

```{r}
## YOUR CODE HERE
plot(m_best, scale = 0, shade = TRUE, trans = linkinv)
```

**Question 5:** Interpret these plots - according to your model, what is the preferred habitat of the California thrasher?

> **Answer:**

> bio1: thrasher is present when annual mean temperature is below ~15 C
> bio12: thrasher is present when annual precip is >500
> bio15: thrasher is present when precip seasonality is >80
> bio8: thrasher is present when mean temp of wettest quarter is >10 C
> bio17: thrasher is present when precip of driest quarter is < 20 

> To summarize: thrasher prefers cooler habitats with decent precipitation (and its variability), but does not prefer excessive precipitation during the dry months (this may reflect chaparral vegetation preferences?). 

There's one problem with this, however - this model is only additive on the link scale. Once we back transform the values, the shape of these smooth terms depends on the values of the other predictors in the model. Instead, we can create a **marginal effects plot** - we plot the effects of each variable, holding the values of the other predictors at some constant value (e.g., their mean). To do this:

1.  Create a data frame with one column containing a range of values for our variable of interest (for example, `bio1`), and with columns for each of the other predictors, each of which is held at their mean.
2.  Obtain model predictions and standard errors by using the `predict()` function on this new data frame.
3.  Back-transform the fitted values, and the fitted values +/- their standard errors to get the upper and lower bounds of our error bands.

**Question 6:** Do this for one of the terms in your model. Interpret the results.

> **Answer:**

```{r}
logit2prob <- function(logit){
  odds <- exp(logit)
  prob <- odds / (1 + odds)
  return(prob)
}
```


```{r}
summary(m_best)
plot(m_best)

# Get median values for all predictors
d_summary <- d %>% 
  gather(key = predictor, value = value, lon, lat, bio1:bio17) %>% 
  group_by(predictor) %>% 
  summarise(median = median(value)) %>% 
  spread(key = predictor, value = median)
d_summary

# Make range of values for predictor of interest
# Choose bio1 (annual mean temperature)
x_range <- range(d$bio1)
x_new <- seq(x_range[1], x_range[2], length.out = 100)

d_new <- tibble(lon = -118, 
                lat = 36, 
                #lon = d_summary$lon, 
                #lat = d_summary$lat, 
                bio1 = x_new, 
                bio8 = d_summary$bio8, 
                bio12 = d_summary$bio12, 
                bio15 = d_summary$bio15, 
                bio16 = d_summary$bio16, 
                bio17 = d_summary$bio17)

d_pred <- predict(object = m_best, newdata = d_new, se.fit = TRUE)

d_pred

d_new <- d_new %>% 
  mutate(fit = d_pred$fit, 
         se = d_pred$se.fit, 
         upper = fit + se, 
         lower = fit - se, 
         fit_prob = logit2prob(fit), 
         upper_prob = logit2prob(upper), 
         lower_prob = logit2prob(lower)
         )

d_new %>% 
  ggplot(aes(x = bio1, 
             y = fit_prob)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower_prob, ymax = upper_prob), alpha = 0.25) + 
  theme_bw() + 
  labs(x = "Annual mean temperature (C)", y = "Probability of occurrence") + 
  ggtitle("Marginal effect (lon = -118, lat = 36, bioclim medians)")
```

## Present

In your group presentation, include 1 slide for each model term in your final model. Show the plot on the log-odds scale and the probability scale, and show the marginal effects plot for the variable you computed it for. Interpret the results for each variable.

# 3 - Project current and future ranges

## Plot distributions - probability of occurrence

BIOCLIM variables across the state of California for 1970-2000 and for the two climate scenarios projected out to 2081-2100 are contained in the `bioclim`, `ssp245`, and `ssp585` data frames.

Obtain fitted probability of occurrence values for each of these data frames:

```{r}
## YOUR CODE HERE
head(bioclim)
bioclim$fitted <- predict(m_best, newdata = bioclim, type = "response")
ssp245$fitted <- predict(m_best, newdata = ssp245, type = "response")
ssp585$fitted <- predict(m_best, newdata = ssp585, type = "response")

```

Plot the current (1970-2000) and projected distributions (under both scenarios) using `ggplot()` and `geom_raster()`. You might also use `scale_color_viridis_c()` with `option = "magma"` - it's better looking and easier to read than the default ggplot color scheme.

```{r}
## YOUR CODE HERE - 1970-2000
bioclim %>% 
  ggplot(aes(lon, lat, fill = fitted)) + 
  scale_fill_viridis_c(option = "magma") +
  geom_raster() + 
  theme_minimal()
```

```{r}
## YOUR CODE HERE - 2081-2100, SSP 2 4.5
ssp245 %>% 
  ggplot(aes(lon, lat, fill = fitted)) + 
  scale_fill_viridis_c(option = "magma") +
  geom_raster() + 
  theme_minimal()
```

```{r}
## YOUR CODE HERE - 2018-2100, SSP 5 8.5
ssp585 %>% 
  ggplot(aes(lon, lat, fill = fitted)) + 
  scale_fill_viridis_c(option = "magma") +
  geom_raster() + 
  theme_minimal()
```

## Plot distributions - presence/absence

To create a map of where we expect thrashers to be present (and where we expect them to be absence), we need to bin the probability of occurrence values estimated by our model. This means we need to choose a threshold probability at which to label the thrasher as "present."

Apply `dismo::threshold()` to the output from `dismo::evaluate()` (that you computed above) to obtain the threshold probability that maximizes the sum of sensitivity and specificity. Create a new column in the `bioclim`, `ssp245`, and `ssp585` data frames indicating whether we expect thrasher to be present or absent in each grid cell:

```{r}
## YOUR CODE HERE
dismo::threshold(ROC)
?thresold
my_threshold <- as.numeric(dismo::threshold(ROC)[2])

bioclim <- bioclim %>% 
  mutate(threshold = my_threshold, 
         present = ifelse(fitted > threshold, 1, 0))

ssp245 <- ssp245 %>% 
  mutate(threshold = my_threshold, 
         present = ifelse(fitted > threshold, 1, 0))

ssp585 <- ssp585 %>% 
  mutate(threshold = my_threshold, 
         present = ifelse(fitted > threshold, 1, 0))

```

Plot these binary presence-absence values across space (let's call this the map of suitable habitat). For aesthetic reasons, it may be good to convert the predicted presence/absence values to character strings, and manually choose colors for "present" and "absent" using the ggplot `scale_color_manual()` function.

```{r}
## YOUR CODE HERE - 1970-2000
bioclim %>% 
  ggplot(aes(lon, lat, fill = as.character(present))) + 
  scale_fill_viridis_d() +
  geom_raster() + 
  theme_minimal()
```

```{r}
## YOUR CODE HERE - 2081-2100, SSP 2 4.5
ssp245 %>% 
  ggplot(aes(lon, lat, fill = as.character(present))) + 
  scale_fill_viridis_d() +
  geom_raster() + 
  theme_minimal()
```

```{r}
## YOUR CODE HERE - 2018-2100, SSP 5 8.5
ssp585 %>% 
  ggplot(aes(lon, lat, fill = as.character(present))) + 
  scale_fill_viridis_d() +
  geom_raster() + 
  theme_minimal()
```

## Present

In your presentation, include 1 slide each for the 1970-2000 distribution, the 2081-2100 distribution under our "middle of the road" scenario, and the 2081-2100 distribution under our "worst case" scenario. In each slide, include both the distribution colored by probability of occurrence and the distribution of suitable habitat.

Interpret the current range and projected range under both scenarios - do the distributional shifts seem feasible / are there any barriers to these distributional shifts occurring that you can think of?

# 4 - Derive range characteristics

## Center of gravity and area occupied

**Question 7:** Compute the mean latitude weighted by probability of occurrence for each of these projections (the latitudinal coordinate of the center of gravity). Under each climate scenario, in which direction do we expect the centroid of the thrasher's range to move (relative to the baseline)?

> **Answer:**

```{r}
## YOUR CODE HERE
bioclim_center <- bioclim %>% 
  summarise(mean_N = weighted.mean(lat, w = present))

ssp245_center <- ssp245 %>% 
  summarise(mean_N = weighted.mean(lat, w = present))

ssp585_center <- ssp585 %>% 
  summarise(mean_N = weighted.mean(lat, w = present))

```

Compute the proportion of California that we expect the California thrasher to occupy for all three fitted maps:

```{r}
## YOUR CODE HERE
bioclim %>% 
  mutate(present_cat = ifelse(present == 0, "absent", "present")) %>% 
  count(present_cat) %>% 
  spread(key = present_cat, value = n) %>%  
  mutate(prop = (present / (absent + present)))

ssp245 %>% 
  mutate(present_cat = ifelse(present == 0, "absent", "present")) %>% 
  count(present_cat) %>% 
  spread(key = present_cat, value = n) %>%  
  mutate(prop = (present / (absent + present)))

ssp585 %>% 
  mutate(present_cat = ifelse(present == 0, "absent", "present")) %>% 
  count(present_cat) %>% 
  spread(key = present_cat, value = n) %>%  
  mutate(prop = (present / (absent + present)))
```

## Present

Include these statistics in your slides alongside your projected distributions. Interpret the results.
